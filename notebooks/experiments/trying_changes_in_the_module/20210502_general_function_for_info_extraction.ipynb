{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime\n",
    "from math import cos, sin, pi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_time_series(list_directories, aggregate_by_months = True,type_of_document = 'F', product_family = 'all'):\n",
    "    \n",
    "    ##Here we define all our empty arrays determined to be our future features:\n",
    "    seasonability_1 = np.empty(0)\n",
    "    seasonability_2 = np.empty(0)\n",
    "    \n",
    "    pmf = np.empty(0)\n",
    "    empty_array = np.empty(0)\n",
    "    \n",
    "    trend = np.empty(0)\n",
    "    number_weeks = range(1,49)\n",
    "    number_months = range(1,13)\n",
    "    \n",
    "    \n",
    "    ## here are the arange divisions when we want to aggregate by weeks:\n",
    "    first_week = np.arange(1,9)\n",
    "    second_week = np.arange(9,17)\n",
    "    third_week = np.arange(17,25)\n",
    "    fourth_week = np.arange(25,32)\n",
    "\n",
    "    first_week_february = np.arange(1,8)\n",
    "    second_week_february = np.arange(8, 15)\n",
    "    third_week_february = np.arange(15, 22)\n",
    "    fourth_week_february = np.arange(22, 30)\n",
    "    \n",
    "    for year in list_directories:\n",
    "        for data in year:\n",
    "                ## we open each year and then each excel related to each month:\n",
    "                df = pd.read_excel(data, engine='openpyxl')\n",
    "                fm = empty_array\n",
    "                \n",
    "                ## we filter only the bill lines which are commercial invices (values 'F' of the 'TipoDoc' Column):\n",
    "                df = df.loc[df['TipoDoc'].isin([type_of_document])]\n",
    "                \n",
    "                ## we filter 'F' documents by its product family if applicable:\n",
    "                if product_family != 'all':\n",
    "                    \n",
    "                    df = df.loc[df['GrupoArticulo'].isin([product_family])]\n",
    "                    \n",
    "                ## we filter the date info inside the fecha column:\n",
    "                df['year'] = pd.DatetimeIndex(df['Fecha']).year\n",
    "                df['month'] = pd.DatetimeIndex(df['Fecha']).month\n",
    "                df['day'] = pd.DatetimeIndex(df['Fecha']).day\n",
    "                \n",
    "                ## in order to know when a line is part of the same bill we stablished that the value for a row\n",
    "                ## in the column 'Linea Doc' it has to be different in the next row when they share the same value in \n",
    "                ## the column 'Documento' (ID number of the document), that's why we use the pandas command shift:\n",
    "                df['siguiente_linea'] = df['LineaDoc'].shift(-1)\n",
    "                df['siguiente_doc'] = df['Documento'].shift(-1)\n",
    "\n",
    "#                 ## now in the last row we will have a NaN value, we should change that:\n",
    "#                 df.loc[np.isnan(df[\"siguiente_linea\"]), 'siguiente_linea'] = df['LineaDoc'][-1:]\n",
    "#                 df.loc[np.isnan(df[\"siguiente_doc\"]), 'siguiente_doc'] = df['Documento'][-1:]\n",
    "                \n",
    "#                 df['siguiente_linea'] = df['siguiente_linea'].astype('int64')\n",
    "#                 df['siguiente_doc'] = df['siguiente_doc'].astype('int64')\n",
    "                \n",
    "                ## let's try to use the pandas' command .drop() in order to implement the mentioned restriction:\n",
    "                df = df.drop(df[(df['Documento'] == df['siguiente_doc']) & (df['LineaDoc'] == df['siguiente_linea'])].index)\n",
    "                \n",
    "                ## if we want to aggregate by months (is the more quick way but you have info less detailed):\n",
    "                if aggregate_by_months == True:\n",
    "                    \n",
    "                    ## we sum up the value of the left rows (commercial invoices), which is the value related to the column 'Importe':\n",
    "                    fm = df['Importe'].sum()\n",
    "                \n",
    "                    ## we append to the general array the result of the fourth weeks of the loaded month:\n",
    "                    pmf = np.append(pmf, fm)\n",
    "      \n",
    "                \n",
    "                ##now we have to take into account (if we aggregate by months we have to different February from the rest):\n",
    "                else:\n",
    "                           \n",
    "                            if df['month'].iloc[0] == 2:\n",
    "                                \n",
    "                                ## the amount billed for every week in february:\n",
    "                                df_w1 = df.loc[df['day'].isin(first_week_february)]\n",
    "                                df_w2 = df.loc[df['day'].isin(second_week_february)]\n",
    "                                df_w3 = df.loc[df['day'].isin(third_week_february)]\n",
    "                                df_w4 = df.loc[df['day'].isin(fourth_week_february)]\n",
    "                        \n",
    "                            else:\n",
    "                                \n",
    "                                ## the amount billed for every \n",
    "                                df_w1 = df.loc[df['day'].isin(first_week)]\n",
    "                                df_w2 = df.loc[df['day'].isin(second_week)]\n",
    "                                df_w3 = df.loc[df['day'].isin(third_week)]\n",
    "                                df_w4 = df.loc[df['day'].isin(fourth_week)]\n",
    "                                ## HERE WE STORE THE VALUES OF OUR COLUMNS:\n",
    "\n",
    "                            ## we generate for each total week the total billed quantity, by filtering the column:\n",
    "                            first_week_importe = df_w1['Importe'].sum()\n",
    "                            second_week_importe = df_w2['Importe'].sum()\n",
    "                            third_week_importe = df_w3['Importe'].sum()\n",
    "                            fourth_week_importe = df_w4['Importe'].sum()\n",
    "\n",
    "                            ## we store the last fourth arrays in one called fm (facturacion del mes, billed amount of the month):\n",
    "                            fm = np.array([first_week_importe,second_week_importe, third_week_importe,fourth_week_importe])\n",
    "\n",
    "                            ## we append to the general array the result of the fourth weeks of the loaded month:\n",
    "                            pmf = np.append(pmf, fm)\n",
    "\n",
    "                            \n",
    "        ## if we want to aggregate by months (is the more quick way but you have info less detailed):\n",
    "        if aggregate_by_months == True:                   \n",
    "            \n",
    "        \n",
    "            ## we store the trend info (passage of time):\n",
    "            ## we store the year:\n",
    "            for month in number_months:\n",
    "                y = df['year'].iloc[0]\n",
    "                trd = y + (month - 1)/12\n",
    "\n",
    "                ## then we store this trend number into an array:\n",
    "                trend = np.append(trend, trd)\n",
    "\n",
    "                ## we save the information of the month:\n",
    "                dt_circ_base = (month/12)*2*pi # entre 0 y 2*pi\n",
    "                features_dt_circ = [cos(dt_circ_base), sin(dt_circ_base)] # 2 valores, a rellenar en 2 columnas de features\n",
    "\n",
    "                ## we store the info of the cos:\n",
    "                seasonability_1 = np.append(seasonability_1, features_dt_circ[0])\n",
    "\n",
    "                ## and the info  of the sin:\n",
    "                seasonability_2 = np.append(seasonability_2, features_dt_circ[1])\n",
    "        else:\n",
    "            \n",
    "            ## we store the trend info (passage of time):\n",
    "            ## we store the year:\n",
    "            for week in number_weeks:\n",
    "                y = df['year'].iloc[0]\n",
    "                trd = y + (week - 1)/48\n",
    "\n",
    "                ## then we store this trend number into an array:\n",
    "                trend = np.append(trend, trd)\n",
    "            \n",
    "                ## we save the information of the month:\n",
    "                dt_circ_base = (week/48)*2*pi # entre 0 y 2*pi\n",
    "                features_dt_circ = [cos(dt_circ_base), sin(dt_circ_base)] # 2 valores, a rellenar en 2 columnas de features\n",
    "            \n",
    "                ## we store the info of the cos:\n",
    "                seasonability_1 = np.append(seasonability_1, features_dt_circ[0])\n",
    "\n",
    "                ## and the info  of the sin:\n",
    "                seasonability_2 = np.append(seasonability_2, features_dt_circ[1])\n",
    "            \n",
    "    ##here after the iterations are done we store the arrays generated:\n",
    "    yTrain = pd.DataFrame({'target':pmf})\n",
    "    \n",
    "    xTrain = pd.DataFrame({'seasonability_circ_cos':seasonability_1,'seasonability_circ_sin':seasonability_2, 'time':trend, 'y_t-1':yTrain.target.shift(1)})\n",
    "    return yTrain, xTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablas20_1 = glob.glob(\"C:/Users/Javier/Documents/GIT/Repositories/TFM-Textil-Santanderina/data/raw/2015*.xlsx\")\n",
    "tablas20_2 = glob.glob(\"C:/Users/Javier/Documents/GIT/Repositories/TFM-Textil-Santanderina/data/raw/2016*.xlsx\")\n",
    "tablas20_3 = glob.glob(\"C:/Users/Javier/Documents/GIT/Repositories/TFM-Textil-Santanderina/data/raw/2017*.xlsx\")\n",
    "tablas20_4 = glob.glob(\"C:/Users/Javier/Documents/GIT/Repositories/TFM-Textil-Santanderina/data/raw/2018*.xlsx\")\n",
    "tablas20_5 = glob.glob(\"C:/Users/Javier/Documents/GIT/Repositories/TFM-Textil-Santanderina/data/raw/2019*.xlsx\")\n",
    "tablas20_all = list([tablas20_1,tablas20_2,tablas20_3, tablas20_4, tablas20_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = df_time_series(list_directories=tablas20_all, aggregate_by_months=False, product_family = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98850728.15"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.target[0:48].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_months = pd.read_pickle(\"C:/Users/Javier/Documents/GIT/Repositories/TFM-Textil-Santanderina/data/processed/time_serie_y_total_production.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95861964.45"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_months.target[0:12].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2, x2 = df_time_series(list_directories=tablas20_all, aggregate_by_months=True, product_family = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98955203.71999998"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.target[0:12].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_pickle(\"C:/Users/Javier/Documents/GIT/Repositories/TFM-Textil-Santanderina/data/processed/weekly_time_series_wholeproduction_value.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2.to_pickle(\"C:/Users/Javier/Documents/GIT/Repositories/TFM-Textil-Santanderina/data/processed/monthly_time_serie_general_function.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
